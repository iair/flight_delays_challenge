{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89eb397-3280-4391-aae1-9a4fa53ec538",
   "metadata": {},
   "source": [
    "# Trained the model with variable selection and with the dataset that already has a dimentional reduction variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5deb4ca-8661-4531-93fe-3a62e07bc60e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d496fb-40e6-42f9-8d1a-ae0238d0ae2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import libraries and declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a87452-779f-49c8-9947-358d8d4d9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Only for final delivery\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "# Libraries models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from time import time\n",
    "# Set some Pandas options\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 25)\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib inline') \n",
    "get_ipython().magic(u\"config InlineBackend.figure_format='retina'\")\n",
    "import seaborn as sns\n",
    "# Library's to apply balance technic's\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the necessary module's\n",
    "from scipy.stats import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler,binarize\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif,chi2,RFE,RFECV,SelectFromModel\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate,cross_val_score\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,precision_score,recall_score,f1_score,average_precision_score\n",
    "from sklearn.metrics import roc_curve,classification_report,confusion_matrix,make_scorer\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "# library to save the models\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ea0947-f69d-43ff-8ba6-53d99fd7ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_na(df):\n",
    "    qsna=df.shape[0]-df.isnull().sum(axis=0)\n",
    "    qna=df.isnull().sum(axis=0)\n",
    "    ppna=round(100*(df.isnull().sum(axis=0)/df.shape[0]),2)\n",
    "    aux= {'datos sin NAs en q': qsna, 'Na en q': qna ,'Na en %': ppna}\n",
    "    na=pd.DataFrame(data=aux)\n",
    "    return na.sort_values(by='Na en %',ascending=False)\n",
    "\n",
    "def plot_pie(y):\n",
    "    target_stats = Counter(y)\n",
    "    labels = list(target_stats.keys())\n",
    "    sizes = list(target_stats.values())\n",
    "    explode = tuple([0.1] * len(target_stats))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(sizes, explode=explode, labels=labels, shadow=True,\n",
    "           autopct='%1.1f%%')\n",
    "    ax.axis('equal')\n",
    "\n",
    "def variable_selection(X,y):\n",
    "    \n",
    "    # Generamos la métrica de mutual information de los features con respecto al Score \n",
    "    mi = mutual_info_classif(X,y,random_state=0,discrete_features='auto')\n",
    "    # Creamos el dataframe con los resultados\n",
    "    raw_data={'features':X.columns.values,'m-score':mi,'m-weight':mi/np.max(mi)}\n",
    "    features_mi=pd.DataFrame(raw_data,columns=['features','m-score','m-weight'])\n",
    "    features_mi=features_mi.sort_values(by='m-weight',ascending=False)\n",
    "    \n",
    "    # Generamos el el clasificador con Random Forest\n",
    "    clf = RandomForestClassifier(\n",
    "        bootstrap=True, criterion='gini',max_features='sqrt',min_samples_split=23,\n",
    "        n_estimators=300,random_state=0,warm_start=True,n_jobs=-1, min_samples_leaf =23)\n",
    "    # Aplicamos el Recursive feature engineer utilizando el modelo de Random Forest\n",
    "    rfe_rf = RFE(clf, n_features_to_select=1)\n",
    "    fit_rf = rfe_rf.fit(X, y)\n",
    "    # Creamos el dataframe con los resultados uniéndolo a los resultados anteriores\n",
    "    raw_data={'features':X.columns.values,'ranking_ffe_rf':fit_rf.ranking_}\n",
    "    features_ffe_rf=pd.DataFrame(\n",
    "        raw_data,columns=['features','ranking_ffe_rf']).sort_values(by='ranking_ffe_rf',ascending=True)\n",
    "    selected_features=pd.merge(left=features_mi,right=features_ffe_rf, how='left', on='features', \n",
    "                               sort=False,suffixes=('_mi', '_ffe_rf'), copy=True, indicator=False)\n",
    "    \n",
    "    # Generamos el el clasificador con Regresión logística\n",
    "    model = LogisticRegression(random_state=0,warm_start=True)\n",
    "    # Aplicamos el Recursive feature engineer utilizando el modelo de Regresión Logística\n",
    "    rfe_lr = RFE(model, n_features_to_select=1)\n",
    "    fit_rl = rfe_lr.fit(X, y)\n",
    "    # Creamos el dataframe con los resultados uniéndolo a los resultados anteriores\n",
    "    raw_data={'features':X.columns.values,'ranking_ffe_rl':fit_rl.ranking_}\n",
    "    features_ffe_rl=pd.DataFrame(\n",
    "        raw_data,columns=['features','ranking_ffe_rl']).sort_values(by='ranking_ffe_rl',ascending=True)\n",
    "    selected_features=pd.merge(left=selected_features,right=features_ffe_rl, how='left', on='features', left_on=None, \n",
    "                               sort=False,suffixes=('', '_ffe_rl'), copy=True, \n",
    "                               indicator=False)\n",
    "    \n",
    "    # Generamos el el clasificador con Gradient Boosting\n",
    "    model = GradientBoostingClassifier(\n",
    "        random_state=0,max_features='sqrt',subsample=0.8,\n",
    "        n_estimators=300,min_samples_split = 20,warm_start=True)\n",
    "    # Aplicamos el Recursive feature engineer utilizando el modelo de Gradient Boosting\n",
    "    rfe_gb = RFE(model, n_features_to_select=1)\n",
    "    fit_gb = rfe_gb.fit(X=X, y=y)\n",
    "    # Creamos el dataframe con los resultados uniéndolo a los resultados anteriores\n",
    "    raw_data={'features':X.columns.values,'ranking_ffe_gb':fit_gb.ranking_}\n",
    "    features_ffe_gb=pd.DataFrame(\n",
    "        raw_data,columns=['features','ranking_ffe_gb']).sort_values(by='ranking_ffe_gb',ascending=True)\n",
    "    selected_features=pd.merge(left=selected_features,right=features_ffe_gb, how='left', on='features',\n",
    "                               suffixes=('', '_ffe_gb'), copy=True, indicator=False)\n",
    "    \n",
    "    # Generamos el el clasificador con Linear SVC\n",
    "    lsvc = LinearSVC(C=1, penalty=\"l1\", random_state=0,dual=False,loss='squared_hinge').fit(X, y)\n",
    "    # Aplicamos el Recursive feature engineer utilizando el modelo de Linear SVC\n",
    "    model = SelectFromModel(lsvc, prefit=True)\n",
    "    X_new = model.transform(X)\n",
    "    # Creamos el dataframe con los resultados uniéndolo a los resultados anteriores\n",
    "    raw_data={'features':X.columns.values,'coef_svc':np.abs(lsvc.coef_[0])}\n",
    "    features_svc=pd.DataFrame(raw_data,columns=['features','coef_svc']).sort_values(by='coef_svc',ascending=False)\n",
    "    features_svc['ranking_svc']=range(1,len(lsvc.coef_[0])+1)\n",
    "    selected_features=pd.merge(left=selected_features,right=features_svc, how='left', on='features',\n",
    "                               sort=False,suffixes=('', '_svc_lineal'), copy=True, indicator=False)\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf427d8-4890-48a7-adf3-dd1bc4f8432b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading pre-processed dataset and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e87f5d2-cc73-4e03-a77f-b7514b9859fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m mca \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#get_na(mca)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(mca, \u001b[43my\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#define data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m [X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "directory_path = os.path.abspath(os.path.join('..'))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "os.chdir(directory_path)\n",
    "path = os.getcwd() + '/data/interim/model_data_mca.csv' \n",
    "mca = pd.read_csv(path, sep=',')\n",
    "#get_na(mca)\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(mca, y, test_size=0.3, random_state=100)\n",
    "#define data\n",
    "data = [X_train.shape[0],X_test.shape[0] ]\n",
    "labels = [data[0], data[1]]\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('bright')[0:2]\n",
    "#create pie chart\n",
    "plt.pie(data, labels = labels, colors = colors,startangle=90, \n",
    "        autopct='%1.f%%',explode=(0.1,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd81f6-3f18-4608-8c53-77fb0858b2d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the models in the dataset with 20 components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a27991-36fe-4ca7-91df-61809226f84b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train the five models and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ab860c-3c32-43bf-a44f-cf6f60600d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0, max_features='sqrt',criterion='gini',\n",
    "                             min_samples_split=0.001)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='precision')\n",
    "print(scores.mean())\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_probs = clf.predict_proba(X_test)[:,1]\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual class'], colnames=['Predicted class'],margins=True)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1f0aa-3d0d-4e7b-806d-c8660643f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500,random_state=0,warm_start=True,criterion='gini',\n",
    "                             bootstrap=True,max_features='sqrt',class_weight = 'balanced')\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='precision')\n",
    "print(scores.mean())\n",
    "clf = RandomForestClassifier(n_estimators=500,random_state=0,warm_start=True,criterion='gini',\n",
    "                             bootstrap=True,max_features='sqrt',class_weight = 'balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict_proba(X_test)[:,1]\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual class'], colnames=['Predicted class'],margins=True)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116e1e4-75ed-4e64-9f3b-022da8461b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='precision')\n",
    "print(scores.mean())\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_probs = clf.predict_proba(X_test)[:,1]\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual class'], colnames=['Predicted class'],margins=True)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01507a1-7683-465e-ba7e-faf6223cda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(random_state=0, verbose=0)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='precision')\n",
    "print(scores.mean())\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_probs = clf.predict_proba(X_test)[:,1]\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual class'], colnames=['Predicted class'],margins=True)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
